{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_all_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0b/fx5b7rgn6rl61000z85h05fw0000gn/T/ipykernel_22205/1257164603.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 数据和测试数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 1.Label Encoding for sparse features,and process sequence features with `gen_date_set` and `gen_model_input`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_all_data' is not defined"
     ]
    }
   ],
   "source": [
    "# 系数特征编码\n",
    "# 针对用户侧和新闻侧的稀疏特征进行编码，并将训练样本join上两侧的特征\n",
    "\n",
    "# 数据和测试数据\n",
    "data, user_data, doc_data = get_all_data()\n",
    "\n",
    "# 1.Label Encoding for sparse features,and process sequence features with `gen_date_set` and `gen_model_input`\n",
    "feature_max_idx = {}\n",
    "feature_encoder = {}\n",
    "\n",
    "user_sparse_features = [\"user_id\", \"device\", \"os\", \"province\", \"city\", \"age\", \"gender\"]\n",
    "for feature in user_sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    user_data[feature] = lbe.fit_transform(user_data[feature]) + 1\n",
    "    feature_max_idx[feature] = user_data[feature].max() + 1\n",
    "    feature_encoder[feature] = lbe\n",
    "\n",
    "\n",
    "doc_sparse_features = [\"article_id\", \"cate\", \"sub_cate\"]\n",
    "doc_dense_features = [\"title_len\", \"img_num\"]\n",
    "\n",
    "for feature in doc_sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    if feature in [\"cate\",\"sub_cate\"]:\n",
    "        # 这里面会出现一些float的数据，导致无法编码\n",
    "        doc_data[feature] = lbe.fit_transform(doc_data[feature].astype(str)) + 1\n",
    "    else:\n",
    "        doc_data[feature] = lbe.fit_transform(doc_data[feature]) + 1\n",
    "    feature_max_idx[feature] = doc_data[feature].max() + 1\n",
    "    feature_encoder[feature] = lbe\n",
    "\n",
    "data[\"article_id\"] = feature_encoder[\"article_id\"].transform(data[\"article_id\"].tolist())\n",
    "data[\"user_id\"] = feature_encoder[\"user_id\"].transform(data[\"user_id\"].tolist())\n",
    "\n",
    "\n",
    "# join 用户侧和新闻侧的特征\n",
    "data = data.join(user_data.set_index(\"user_id\"), on=\"user_id\", how=\"inner\")\n",
    "data = data.join(doc_data.set_index(\"article_id\"), on=\"article_id\", how=\"inner\")\n",
    "\n",
    "sparse_features = user_sparse_features + doc_sparse_features\n",
    "dense_features = doc_dense_features\n",
    "\n",
    "features = sparse_features + dense_features\n",
    "\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置特征以及模型训练\n",
    "# 构建模型所需要的输入特征，同时构建DSSM模型并且训练\n",
    "from model import DSSM\n",
    "embedding_dim = 8\n",
    "user_feature_columns = [SparseFeat('user_id', feature_max_idx['user_id'], embedding_dim),\n",
    "                        SparseFeat(\"gender\", feature_max_idx['gender'], embedding_dim),\n",
    "                        SparseFeat(\"age\", feature_max_idx['age'], embedding_dim),\n",
    "                        SparseFeat(\"device\", feature_max_idx['device'], embedding_dim),\n",
    "                        SparseFeat(\"os\", feature_max_idx['os'], embedding_dim),\n",
    "                        SparseFeat(\"province\", feature_max_idx['province'], embedding_dim),\n",
    "                        SparseFeat(\"city\", feature_max_idx['city'], embedding_dim),  ]\n",
    "\n",
    "item_feature_columns = [SparseFeat('article_id', feature_max_idx['article_id'], embedding_dim),\n",
    "                        DenseFeat('img_num', 1),\n",
    "                        DenseFeat('title_len', 1),\n",
    "                        SparseFeat('cate', feature_max_idx['cate'], embedding_dim),\n",
    "                        SparseFeat('sub_cate', feature_max_idx['sub_cate'], embedding_dim)]\n",
    "\n",
    "model = DSSM(user_feature_columns, item_feature_columns,\n",
    "          user_dnn_hidden_units=(32, 16, embedding_dim), item_dnn_hidden_units=(32, 16, embedding_dim))  # FM(user_feature_columns,item_feature_columns)\n",
    "\n",
    "model.compile(optimizer=\"adagrad\", loss = \"binary_crossentropy\", metrics=[tf.keras.metrics.Recall(), tf.keras.metrics.Precision()] ) #\n",
    "\n",
    "history = model.fit(train_model_input, train_label, batch_size=256, epochs=4, verbose=1, validation_split=0.2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成embedding用于召回\n",
    "# 利用巡礼过的模型获取所有item的embeddings，同时获取所有测试集的user embedding\n",
    "all_item_model_input = {\"article_id\": item_profile['article_id'].values,\n",
    "                        \"img_num\": item_profile['img_num'].values,\n",
    "                        \"title_len\": item_profile['title_len'].values,\n",
    "                        \"cate\": item_profile['cate'].values,\n",
    "                        \"sub_cate\": item_profile['sub_cate'].values,}\n",
    "\n",
    "user_embedding_model = Model(inputs=model.user_input, outputs=model.user_embedding)\n",
    "item_embedding_model = Model(inputs=model.item_input, outputs=model.item_embedding)\n",
    "\n",
    "user_embs = user_embedding_model.predict(test_user_model_input, batch_size=2 ** 12)\n",
    "item_embs = item_embedding_model.predict(all_item_model_input, batch_size=2 ** 12)\n",
    "\n",
    "user_idx_2_rawid, doc_idx_2_rawid = {}, {}\n",
    "\n",
    "for i in range(len(user_embs)):\n",
    "    user_idx_2_rawid[i] = test_user_model_input[\"user_id\"][i]\n",
    "\n",
    "    for i in range(len(item_embs)):\n",
    "        doc_idx_2_rawid[i] = all_item_model_input[\"article_id\"][i]\n",
    "\n",
    "        # 保存一份\n",
    "        pickle.dump((user_embs, user_idx_2_rawid, feature_encoder[\"user_id\"]), open(file_path + 'user_embs.pkl', 'wb'))\n",
    "        pickle.dump((item_embs, doc_idx_2_rawid, feature_encoder[\"article_id\"]), open(file_path + 'item_embs.pkl', 'wb'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
